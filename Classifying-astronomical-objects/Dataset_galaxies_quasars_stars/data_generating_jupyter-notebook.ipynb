{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rzHmWfhy8-v8"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import torch\n","\n","# Code samples taken from: https://github.com/informationcake/SDSS-ML/blob/master/SDSS_ML.py\n","# Cite dataset as: A. O. Clarke, A. M. M. Scaife, R. Greenhalgh, & V. Griguta. (2020). Identifying galaxies, quasars and stars with machine learning: a new catalogue of classifications for 111 million SDSS sources without spectra [Data set]. Zenodo. [https://doi.org/10.5281/zenodo.3768398](https://doi.org/10.5281/zenodo.3768398)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQ3EvOt48-v_"},"outputs":[],"source":["#Loading/saving python data objects\n","def save_obj(obj, name ):\n","    with open(name + '.pkl', 'wb') as f:\n","        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n","\n","def load_obj(name ):\n","    with open(name + '.pkl', 'rb') as f:\n","        return pickle.load(f)\n","\n","# Take input data, prepare for supervised ML or TSNE\n","def prepare_data(data, feature_columns, train_percent=0.5, ttsplit=True, mag_split=False, mag_lim=18.5, ttbelow=True, scale=False, verbose=False, newsources=False):\n","    print('Preparing data... Its shape is: {0}'.format(data.shape))\n","    #test/train split using sklearn function\n","    if ttsplit==True and mag_split==False:\n","        all_features = data[[*feature_columns]]\n","        if newsources==False:\n","            all_classes = data['class']\n","        if newsources==True:\n","            all_classes = data['class_pred']\n","        if scale==True:\n","            print('Scaling features...')\n","            #all_features = preprocessing.scale(all_features)\n","            all_features = preprocessing.normalize(all_features)\n","            all_features = pd.DataFrame(all_features)\n","        features_train, features_test, classes_train, classes_test = train_test_split(all_features, all_classes, train_size=train_percent, random_state=0, stratify=all_classes)\n","        class_names = np.unique(all_classes)\n","        feature_names = list(all_features)\n","        #print(isinstance(classes_train, pd.DataFrame))\n","        if verbose==True: print('feature names are: ', str(feature_names))\n","        return {'features_train':features_train, 'features_test':features_test, 'classes_train':classes_train, 'classes_test':classes_test, 'class_names':class_names, 'feature_names':feature_names} #return dictionary. data within dictionary are DataFrames.\n","\n","    #test/train split only below a PSF magnitude limit in r band\n","    if ttsplit==True and mag_split==True:\n","        if ttbelow==True:\n","            print('Imposing magnitude cut of cmod_r={0}, performing test/train split below this...'.format(mag_lim))\n","            data_tt = data[data.psf_r < mag_lim] # split out brighter fraction of data before tt split\n","            data_new = data[data.psf_r > mag_lim] # set aside fraction of fainter new sources (e.g. simulating deeper data)\n","        if ttbelow==False:\n","            print('Imposing magnitude cut of cmod_r={0}, performing test/train split above this...'.format(mag_lim))\n","            data_tt = data[data.psf_r > mag_lim] # split out fainter fraction of data before tt split\n","            data_new = data[data.psf_r < mag_lim] # set aside fraction of brighter sources\n","        all_features = data_tt[[*feature_columns]]\n","        all_classes = data_tt['class']\n","        print('Number of sources not in tt-split: {0}'.format(len(data_new)))\n","        # do tt split\n","        features_train, features_test, classes_train, classes_test = train_test_split(all_features, all_classes, train_size=train_percent, random_state=0, stratify=all_classes)\n","        # append the data_new deeper sources not included in tt split to the arrays\n","        features_test = features_test.append( data_new[[*feature_columns]] )\n","        classes_test = classes_test.append( data_new['class'] )\n","        print('Training on \\n{0}'.format(classes_train.value_counts()))\n","        print('Testing on \\n{0}'.format(classes_test.value_counts()))\n","        # get names as strings\n","        class_names = np.unique(data['class'])\n","        feature_names = list(data[[*feature_columns]])\n","        if verbose==True: print('feature names are: ', str(feature_names))\n","\n","        return {'features_train':features_train, 'features_test':features_test, 'classes_train':classes_train, 'classes_test':classes_test, 'class_names':class_names, 'feature_names':feature_names} #return dictionary\n","\n","\n","    #no test/train split, just return data in format for e.g. tsne or clustering\n","    if ttsplit==False:\n","        all_features = data[[*feature_columns]]\n","        all_classes = data['class']\n","        class_names = np.unique(data['class'])\n","        return {'all_features':all_features, 'all_classes':all_classes, 'class_names':class_names} #return dictionary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OENmVCkF8-wB","outputId":"d22eef08-b7dc-4333-ae48-be63cfa738cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["features used are:\n","Index(['psf_u', 'psf_g', 'psf_r', 'psf_i', 'psf_z', 'w1', 'w2', 'w3', 'w4',\n","       'resolvedr'],\n","      dtype='object')\n"]}],"source":["# define feature columns used\n","# psf magnitudes\n","psf = ['psf_u', 'psf_g', 'psf_r', 'psf_i', 'psf_z']\n","# WISE magnitudes\n","wise = ['w1' ,'w2', 'w3', 'w4']\n","# Select columns to be used as features (typical combinations tested, commented in/out)\n","feature_columns = psf + wise + ['resolvedr']\n","\n","df = load_obj('data/Identifying_galaxies_quasars_stars/df_spec_classprobs')\n","print('features used are:')\n","print(df[feature_columns].columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tStk5FYk8-wE","outputId":"33111e51-62ab-405f-ca12-a5ec8216b560"},"outputs":[{"data":{"text/plain":["(3099457, 64)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VwF7J4qY8-wF","outputId":"fe92f4bc-262f-4d79-8884-b627dcefb282"},"outputs":[{"name":"stdout","output_type":"stream","text":["GALAXY    2209333\n","STAR       512236\n","QSO        377888\n","Name: class, dtype: int64\n"]}],"source":["print(df['class'].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DoCvPgq18-wF","outputId":"5e9b0ffb-ee6f-4f74-92ff-0fbb449d8c1e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Preparing data... Its shape is: (3099457, 64)\n"]}],"source":["data_prep_dict_all = prepare_data(df, feature_columns, ttsplit=True, mag_split=False, mag_lim=18, ttbelow=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fwfvN-878-wG"},"outputs":[],"source":["# write out subsample of data for unsupervised processing:\n","tsne_subsample = data_prep_dict_all['features_test'].sample(10000, random_state = 42 ).values\n","tsne_subsample_classes = data_prep_dict_all['classes_test'].sample(10000, random_state = 42 ).values\n","# save out for using in unsupervised learning:\n","pickle.dump( (tsne_subsample,tsne_subsample_classes), open( \"data/Identifying_galaxies_quasars_stars/subdf_unsupervised.pickle\", \"wb\" ))"]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:Orange]","language":"python","name":"conda-env-Orange-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}